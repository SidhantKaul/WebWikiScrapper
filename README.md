# ğŸ“˜ WebWikiScrapper

**WebWikiScrapper** is a Go-based command-line tool that scrapes and extracts structured data from Wikipedia pages. It fetches summary sections and infobox tables efficiently, making it ideal for:

- ğŸ“Š Data analysis  
- ğŸ” Research  
- ğŸ“š Content aggregation  

---

## âœ¨ Features

- âœ… **Wikipedia Data Extraction**  
  Automatically scrapes page summaries and infobox tables from any Wikipedia article.

- âœ… **Structured Output**  
  Outputs clean, structured data in **JSON** format for easy parsing and downstream use.

- âœ… **Modular Design**  
  Built using a scalable architecture with the following key modules:
  - `scrapper`: Core scraping logic  
  - `jsonwriter`: Handles JSON data export  
  - `graph`: Utilities for graph-related structures or relationships  

---

## ğŸš€ Getting Started

### ğŸ“¥ Clone the Repository

```bash
git clone https://github.com/SidhantKaul/WebWikiScrapper.git
cd WebWikiScrapper
